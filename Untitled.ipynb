{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a470b23-84e5-4efc-be80-0c5124d8b027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Collecting numpy\n",
      "  Using cached numpy-2.1.2-cp312-cp312-win_amd64.whl.metadata (59 kB)\n",
      "Collecting keras\n",
      "  Downloading keras-3.6.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.17.0-cp312-cp312-win_amd64.whl.metadata (3.2 kB)\n",
      "Collecting nltk\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting absl-py (from keras)\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting rich (from keras)\n",
      "  Downloading rich-13.9.2-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras)\n",
      "  Using cached namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting h5py (from keras)\n",
      "  Using cached h5py-3.12.1-cp312-cp312-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting optree (from keras)\n",
      "  Downloading optree-0.13.0-cp312-cp312-win_amd64.whl.metadata (48 kB)\n",
      "Collecting ml-dtypes (from keras)\n",
      "  Downloading ml_dtypes-0.5.0-cp312-cp312-win_amd64.whl.metadata (22 kB)\n",
      "Requirement already satisfied: packaging in f:\\python\\internship tasks\\sentiment_analysis\\myenv\\lib\\site-packages (from keras) (24.1)\n",
      "Collecting tensorflow-intel==2.17.0 (from tensorflow)\n",
      "  Using cached tensorflow_intel-2.17.0-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting ml-dtypes (from keras)\n",
      "  Using cached ml_dtypes-0.4.1-cp312-cp312-win_amd64.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached protobuf-4.25.5-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in f:\\python\\internship tasks\\sentiment_analysis\\myenv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in f:\\python\\internship tasks\\sentiment_analysis\\myenv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in f:\\python\\internship tasks\\sentiment_analysis\\myenv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting typing-extensions>=3.6.6 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached wrapt-1.16.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached grpcio-1.66.2-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.18,>=2.17 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached tensorboard-2.17.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Collecting click (from nltk)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting joblib (from nltk)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2024.9.11-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Collecting tqdm (from nltk)\n",
      "  Using cached tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: colorama in f:\\python\\internship tasks\\sentiment_analysis\\myenv\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in f:\\python\\internship tasks\\sentiment_analysis\\myenv\\lib\\site-packages (from rich->keras) (2.18.0)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached wheel-0.44.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in f:\\python\\internship tasks\\sentiment_analysis\\myenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in f:\\python\\internship tasks\\sentiment_analysis\\myenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in f:\\python\\internship tasks\\sentiment_analysis\\myenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in f:\\python\\internship tasks\\sentiment_analysis\\myenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2024.8.30)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached werkzeug-3.0.4-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in f:\\python\\internship tasks\\sentiment_analysis\\myenv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.0.1)\n",
      "Downloading keras-3.6.0-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.3/1.2 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.3/1.2 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.3/1.2 MB ? eta -:--:--\n",
      "   ----------------- ---------------------- 0.5/1.2 MB 419.4 kB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 0.5/1.2 MB 419.4 kB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 0.5/1.2 MB 419.4 kB/s eta 0:00:02\n",
      "   -------------------------- ------------- 0.8/1.2 MB 419.4 kB/s eta 0:00:01\n",
      "   -------------------------- ------------- 0.8/1.2 MB 419.4 kB/s eta 0:00:01\n",
      "   -------------------------- ------------- 0.8/1.2 MB 419.4 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.0/1.2 MB 426.5 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.0/1.2 MB 426.5 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.0/1.2 MB 426.5 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.0/1.2 MB 426.5 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.0/1.2 MB 426.5 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.0/1.2 MB 426.5 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.2/1.2 MB 290.0 kB/s eta 0:00:00\n",
      "Using cached tensorflow-2.17.0-cp312-cp312-win_amd64.whl (2.0 kB)\n",
      "Using cached tensorflow_intel-2.17.0-cp312-cp312-win_amd64.whl (385.2 MB)\n",
      "Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Using cached h5py-3.12.1-cp312-cp312-win_amd64.whl (3.0 MB)\n",
      "Using cached ml_dtypes-0.4.1-cp312-cp312-win_amd64.whl (127 kB)\n",
      "Downloading regex-2024.9.11-cp312-cp312-win_amd64.whl (273 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.13.0-cp312-cp312-win_amd64.whl (283 kB)\n",
      "Downloading rich-13.9.2-py3-none-any.whl (242 kB)\n",
      "Using cached tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Using cached grpcio-1.66.2-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Using cached protobuf-4.25.5-cp310-abi3-win_amd64.whl (413 kB)\n",
      "Using cached tensorboard-2.17.1-py3-none-any.whl (5.5 MB)\n",
      "Downloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached wrapt-1.16.0-cp312-cp312-win_amd64.whl (37 kB)\n",
      "Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached werkzeug-3.0.4-py3-none-any.whl (227 kB)\n",
      "Using cached wheel-0.44.0-py3-none-any.whl (67 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, werkzeug, typing-extensions, tqdm, termcolor, tensorboard-data-server, regex, protobuf, opt-einsum, numpy, mdurl, markdown, joblib, grpcio, google-pasta, gast, click, absl-py, tensorboard, optree, nltk, ml-dtypes, markdown-it-py, h5py, astunparse, rich, keras, tensorflow-intel, tensorflow\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 click-8.1.7 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.66.2 h5py-3.12.1 joblib-1.4.2 keras-3.6.0 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.1 namex-0.0.8 nltk-3.9.1 numpy-1.26.4 opt-einsum-3.4.0 optree-0.13.0 protobuf-4.25.5 regex-2024.9.11 rich-13.9.2 tensorboard-2.17.1 tensorboard-data-server-0.7.2 tensorflow-2.17.0 tensorflow-intel-2.17.0 termcolor-2.5.0 tqdm-4.66.5 typing-extensions-4.12.2 werkzeug-3.0.4 wheel-0.44.0 wrapt-1.16.0\n"
     ]
    }
   ],
   "source": [
    "pip install numpy keras tensorflow nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27d22901-c636-417e-8c5a-c9be4ba23ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from numpy import array\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM,Dropout\n",
    "from keras.layers import Embedding, Bidirectional\n",
    "from keras.preprocessing import sequence\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import load_model\n",
    "import re\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2adf8bf2-5b24-4646-917d-905647a5e361",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = 10000  #vocabulary_size\n",
    "(X_train, y_train), (X_test,y_test) = imdb.load_data(num_words = top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be3962df-0ad9-49aa-a009-8909e3e5f801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------review with words---------\n",
      "['the', 'boiled', 'full', 'involving', 'to', 'impressive', 'boring', 'this', 'as', 'murdering', 'naschy', 'br', 'villain', 'and', 'suggestion', 'need', 'has', 'of', 'costumes', 'b', 'message', 'to', 'may', 'of', 'props', 'this', 'and', 'concentrates', 'concept', 'issue', 'skeptical', 'to', \"god's\", 'he', 'is', 'and', 'unfolds', 'movie', 'women', 'like', \"isn't\", 'surely', \"i'm\", 'and', 'to', 'toward', 'in', \"here's\", 'for', 'from', 'did', 'having', 'because', 'very', 'quality', 'it', 'is', 'and', 'starship', 'really', 'book', 'is', 'both', 'too', 'worked', 'carl', 'of', 'and', 'br', 'of', 'reviewer', 'closer', 'figure', 'really', 'there', 'will', 'originals', 'things', 'is', 'far', 'this', 'make', 'mistakes', 'and', 'was', \"couldn't\", 'of', 'few', 'br', 'of', 'you', 'to', \"don't\", 'female', 'than', 'place', 'she', 'to', 'was', 'between', 'that', 'nothing', 'dose', 'movies', 'get', 'are', 'and', 'br', 'yes', 'female', 'just', 'its', 'because', 'many', 'br', 'of', 'overly', 'to', 'descent', 'people', 'time', 'very', 'bland']\n",
      "-------labels-----------\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "word2id = imdb.get_word_index()\n",
    "id2word = {i: word for word, i in word2id.items()}\n",
    "print(\"-------review with words---------\")\n",
    "print([id2word.get(i, ' ') for i in X_train[6]])\n",
    "print(\"-------labels-----------\")\n",
    "print(y_train[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46c41c53-a760-41af-b3d3-cae99392a49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_review_length = 200\n",
    "X_train = sequence.pad_sequences(X_train,maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test,maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ef36a7e-16ae-49c7-b1b9-6cb11b41cea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\python\\internship tasks\\Sentiment_Analysis\\myenv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m552s\u001b[0m 1s/step - accuracy: 0.7005 - loss: 0.5387 - val_accuracy: 0.8700 - val_loss: 0.3153\n",
      "Epoch 2/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m464s\u001b[0m 1s/step - accuracy: 0.9075 - loss: 0.2425 - val_accuracy: 0.8681 - val_loss: 0.3261\n",
      "Epoch 3/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m473s\u001b[0m 1s/step - accuracy: 0.9383 - loss: 0.1744 - val_accuracy: 0.8461 - val_loss: 0.4039\n",
      "Epoch 4/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m523s\u001b[0m 1s/step - accuracy: 0.9542 - loss: 0.1321 - val_accuracy: 0.8621 - val_loss: 0.3849\n"
     ]
    }
   ],
   "source": [
    "embedding_vector_length = 100\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vector_length, input_length=max_review_length))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Bidirectional(LSTM(32)))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Use early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), \n",
    "                    epochs=10, batch_size=64, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06600915-f770-427b-9847-755364e21264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%Accuracy: 0.87%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test,y_test,verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % scores[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "046c6021-b6e5-4f0f-aef1-51ea145b7629",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model successfully\n"
     ]
    }
   ],
   "source": [
    "model.save(\"sentiment_analysis_model_new.h5\")\n",
    "print(\"saved model successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5273c034-7f3e-462d-b3df-403bd91a3016",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model successfully\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"sentiment_analysis_model_new.h5\")\n",
    "print(\"load model successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94171f17-d9f0-476f-b234-6cbe23917468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255cfcf8-31ef-4d5d-b914-7228bbcc34a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
